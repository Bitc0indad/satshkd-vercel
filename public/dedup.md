##Here's a line-by-line explanation of the Python program called "dedup.py"


Before we review please go through the program in its entirety before breaking out line by line to have the mental reference point: 

![Code Snippet](/Users/tobiasmele/Code_Projects/4 Misc/Deduplicate Python Snippet.png)

**Lines 1-3**

```
import pandas as pd
from datetime import timedelta, datetime
import json
```
These are import statements that import the necessary libraries/modules: pandas for data manipulation, datetime for handling dates, and json for reading in JSON files.

**Lines 5-9**

```
def get_data_from_file(datafile):
    with open(datafile, 'r') as f:
        data = json.load(f)
    df = pd.DataFrame(data)
    return format_df(df)
```

This defines the **get_data_from_file** function, which takes a filename as an argument. 

Within the function, the file is opened and read as a JSON file using **json.load**. 

The resulting data is then converted to a pandas DataFrame using **pd.DataFrame**. 

Finally, the DataFrame is passed to the **format_df** function, and the result is returned.

**Lines 13-34**

```
def format_df(df):
    # Remove duplicates
    df = df.loc[~df.index.duplicated(keep='last')]
    
    # Convert index to datetime and resample to daily frequency
    df.index = pd.to_datetime(df.index)
    df = df.resample('D').ffill()
    
    # Check for missing and duplicate dates
    start_date = df.index[0].date()
    end_date = df.index[-1].date()
    expected_dates = pd.date_range(start=start_date, end=end_date, freq='D')
    missing_dates = expected_dates.difference(df.index)
    duplicate_dates = df.index[df.index.duplicated(keep='last')].unique()
    
    # Print information about missing and duplicate dates
    if len(missing_dates) > 0:
        print(f"The following dates are missing: {', '.join(map(str, missing_dates.date))}")
    if len(duplicate_dates) > 0:
        print(f"The following dates are duplicated: {', '.join(map(str, duplicate_dates.date))}")
    
    # Save updated data to file
    df.to_csv("output.txt")
    return df
```

- Testing each function one by one, meaning test duplicate date first then missing time
- When using Chat GPT code sometimes provide non-working code
- Write dedup to one file then and break it rename the function seperately with seperate output file
- SOLID Principles, S - Single Purpose of on method
- New rule be able to debug one function at a time 

This defines the **format_df** function, which takes a DataFrame as an argument. 

The function first removes any duplicate rows based on the index using **~df.index.duplicated(keep='last')**. 

Then it converts the index to datetime using **pd.to_datetime** and resamples the data to a daily frequency using **df.resample('D').ffill()**. 

The resulting DataFrame is then checked for missing and duplicate dates. 

The missing dates are obtained by generating a range of expected dates using **pd.date_range** and finding the difference between that and the actual index using **expected_dates.difference(df.index)**. 

The duplicate dates are obtained using **df.index[df.index.duplicated(keep='last')].unique()**. If there are any missing or duplicate dates, the function prints a message indicating which dates are missing or duplicated. 

Finally, the updated DataFrame is saved to a CSV file named "output.txt" using **df.to_csv**, and the DataFrame is returned.

**Lines 36-38**

```
if __name__ == "__main__":
    datafile = "hkd_historical"
    formatted_data = get_data_from_file(datafile)
```

This is the main program that checks if the script is being run as the main module (i.e. not imported as a module by another script). 

If it is being run as the main module, it sets the **datafile** variable to the string "hkd_historical" (which is assumed to be a filename), and calls the **get_data_from_file** function with **datafile** as an argument. 

The resulting **formatted data** is assigned to the formatted_data variable, although this variable is not used elsewhere in the script.

References:

https://github.com/bitkarrot/dca-calculator/blob/f66c07c02ee11d1f74880314fb0cc92151faa452/cache_data.py#L47

```
def get_data_from_file(datafile):
    data = None
    with open(datafile, "+r") as f:
        raw = f.read()
        data = json.loads(raw)
        df = pd.json_normalize(data)
        return format_df(df)
```


https://github.com/bitkarrot/dca-calculator/blob/f66c07c02ee11d1f74880314fb0cc92151faa452/app.py#L34

```
# Check for duplicates
duplicates = df.index.duplicated(keep="first")
# Remove duplicate rows
df = df[~duplicates]
```
